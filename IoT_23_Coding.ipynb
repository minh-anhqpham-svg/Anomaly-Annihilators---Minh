{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FL3qYziaS7B",
        "outputId": "417f439b-9b82-49dc-dd09-942d5ca8f112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Coercing to numeric: 100%|██████████| 20/20 [00:00<00:00, 1525.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame shape: (237, 23)\n",
            "\n",
            "Label distribution:\n",
            " label\n",
            "0    211\n",
            "1     26\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the path to the log file\n",
        "log_file_path = '/content/conn.log.labeled'\n",
        "\n",
        "# Read the file line by line\n",
        "with open(log_file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Find the header line (starts with #fields) and the types line (starts with #types)\n",
        "header_line = None\n",
        "types_line = None\n",
        "data_start_index = -1\n",
        "\n",
        "for i, line in enumerate(lines):\n",
        "    if line.startswith('#fields'):\n",
        "        header_line = line.strip()\n",
        "    elif line.startswith('#types'):\n",
        "        types_line = line.strip()\n",
        "        data_start_index = i + 1 # Data starts after the types line\n",
        "    elif not line.startswith('#'):\n",
        "        # Stop searching for header/types once data lines are encountered\n",
        "        break\n",
        "\n",
        "# Parse the header line to get column names\n",
        "if header_line:\n",
        "    # Remove '#fields\\t' prefix\n",
        "    header_parts = header_line.replace('#fields\\t', '').split('\\t')\n",
        "    # The last part contains multiple column names separated by spaces\n",
        "    # Assuming the last part is 'tunnel_parents label detailed-label'\n",
        "    last_part = header_parts[-1]\n",
        "    last_cols = last_part.split()\n",
        "    columns = header_parts[:-1] + last_cols\n",
        "else:\n",
        "    raise ValueError(\"Header line not found in the log file.\")\n",
        "\n",
        "# Determine the number of columns before the last three (tunnel_parents, label, detailed-label)\n",
        "num_initial_cols = len(columns) - 3\n",
        "\n",
        "# Parse data rows with more robust splitting for the last columns\n",
        "data_rows_split = []\n",
        "if data_start_index != -1:\n",
        "    for line in lines[data_start_index:]:\n",
        "        if line.strip() and not line.startswith('#'): # Ensure the line is not empty or a comment\n",
        "            row_data = line.strip().split('\\t')\n",
        "\n",
        "            # Check if there are enough initial columns separated by tab\n",
        "            if len(row_data) >= num_initial_cols:\n",
        "                initial_cols_data = row_data[:num_initial_cols]\n",
        "                # The rest of the line should contain the last three columns\n",
        "                remaining_part = '\\t'.join(row_data[num_initial_cols:])\n",
        "\n",
        "                # Split the remaining part by spaces to get the last three columns\n",
        "                last_cols_data = remaining_part.split()\n",
        "\n",
        "                # Ensure we get exactly 3 columns from the last part\n",
        "                if len(last_cols_data) == 3:\n",
        "                    full_row_data = initial_cols_data + last_cols_data\n",
        "                    # Check if the total number of columns matches the header\n",
        "                    if len(full_row_data) == len(columns):\n",
        "                        data_rows_split.append(full_row_data)\n",
        "                    else:\n",
        "                         print(f\"Skipping row due to final column count mismatch. Expected {len(columns)}, got {len(full_row_data)}: {line.strip()}\")\n",
        "                else:\n",
        "                     print(f\"Skipping row due to incorrect number of last columns ({len(last_cols_data)} instead of 3): {line.strip()}\")\n",
        "            else:\n",
        "                print(f\"Skipping row due to insufficient initial columns ({len(row_data)}): {line.strip()}\")\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"Data start index not found in the log file.\")\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "df = pd.DataFrame(data_rows_split, columns=columns)\n",
        "\n",
        "# Ensure 'label' column is treated as string and strip whitespace\n",
        "if 'label' in df.columns:\n",
        "    df['label'] = df['label'].astype(str).str.strip()\n",
        "else:\n",
        "    raise ValueError(\"'label' column not found in DataFrame after parsing.\")\n",
        "\n",
        "# Define the correct label mapping\n",
        "label_mapping = {'Benign': 0, 'Malicious': 1}\n",
        "\n",
        "# Map the stripped labels to numerical values, handling potential missing/unexpected values with NaN\n",
        "df['label'] = df['label'].map(label_mapping)\n",
        "\n",
        "# Identify columns to coerce to numeric (exclude 'uid', 'detailed-label', and the 'label' column which is now numeric)\n",
        "numeric_cols = [col for col in df.columns if col not in ['uid', 'detailed-label', 'label']]\n",
        "\n",
        "# Coerce identified columns to numeric types, coercing errors to NaN\n",
        "for col in tqdm(numeric_cols, desc=\"Coercing to numeric\"):\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Print the shape of the final DataFrame\n",
        "print(\"\\nDataFrame shape:\", df.shape)\n",
        "\n",
        "# Print the value counts for the 'label' column\n",
        "print(\"\\nLabel distribution:\\n\", df['label'].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Create derived features\n",
        "# Handle potential division by zero by adding a small epsilon or checking for zero\n",
        "epsilon = 1e-6\n",
        "\n",
        "# Bytes per packet (handling zero packets)\n",
        "df['orig_bytes_per_pkt'] = df['orig_bytes'] / (df['orig_pkts'] + epsilon)\n",
        "df['resp_bytes_per_pkt'] = df['resp_bytes'] / (df['resp_pkts'] + epsilon)\n",
        "\n",
        "# Duration per byte (handling zero bytes and zero duration)\n",
        "df['duration_per_orig_byte'] = df['duration'] / (df['orig_bytes'] + epsilon)\n",
        "df['duration_per_resp_byte'] = df['duration'] / (df['resp_bytes'] + epsilon)\n",
        "\n",
        "# Packet rate (handling zero duration)\n",
        "df['orig_pkt_rate'] = df['orig_pkts'] / (df['duration'] + epsilon)\n",
        "df['resp_pkt_rate'] = df['resp_pkts'] / (df['duration'] + epsilon)\n",
        "\n",
        "# Byte rate (handling zero duration)\n",
        "df['orig_byte_rate'] = df['orig_bytes'] / (df['duration'] + epsilon)\n",
        "df['resp_byte_rate'] = df['resp_bytes'] / (df['duration'] + epsilon)\n",
        "\n",
        "# Ratio of origin to response bytes/packets\n",
        "df['orig_resp_byte_ratio'] = df['orig_bytes'] / (df['resp_bytes'] + epsilon)\n",
        "df['orig_resp_pkt_ratio'] = df['orig_pkts'] / (df['resp_pkts'] + epsilon)\n",
        "\n",
        "# 2. Identify numerical and categorical features\n",
        "# Exclude 'label', 'uid', and 'detailed-label'\n",
        "excluded_cols = ['label', 'uid', 'detailed-label']\n",
        "all_features = [col for col in df.columns if col not in excluded_cols]\n",
        "\n",
        "# Separate numerical and categorical features based on dtype\n",
        "numerical_features = df[all_features].select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = df[all_features].select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "print(\"Numerical features:\", numerical_features)\n",
        "print(\"Categorical features:\", categorical_features)\n",
        "\n",
        "# 3. Define preprocessing steps for numerical features\n",
        "# Impute with median, then scale\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# 4. Define preprocessing steps for categorical features\n",
        "# Impute with a constant 'missing', then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# 5. Build a ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "print(\"\\nColumnTransformer built successfully.\")\n",
        "display(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "_KK2aAf5aXK5",
        "outputId": "1769f5b5-0f8a-4ac9-f56f-dea3671c1904"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical features: ['ts', 'id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'proto', 'service', 'duration', 'orig_bytes', 'resp_bytes', 'conn_state', 'local_orig', 'local_resp', 'missed_bytes', 'history', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'tunnel_parents', 'orig_bytes_per_pkt', 'resp_bytes_per_pkt', 'duration_per_orig_byte', 'duration_per_resp_byte', 'orig_pkt_rate', 'resp_pkt_rate', 'orig_byte_rate', 'resp_byte_rate', 'orig_resp_byte_ratio', 'orig_resp_pkt_ratio']\n",
            "Categorical features: []\n",
            "\n",
            "ColumnTransformer built successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             ts                 uid  id.orig_h  id.orig_p  id.resp_h  \\\n",
              "0  1.547151e+09  CzsY0D4B96NTr8m7ld        NaN      59222        NaN   \n",
              "1  1.547151e+09  CGEJbl3RNkmXzmkEd4        NaN      59224        NaN   \n",
              "2  1.547151e+09   CVMYDw4wnZfqWrOfd        NaN      59224        NaN   \n",
              "3  1.547151e+09   CXKZmpx40udvITEN2        NaN      59224        NaN   \n",
              "4  1.547151e+09   CBjcNy4pOh8Xg1H4S        NaN      59224        NaN   \n",
              "\n",
              "   id.resp_p  proto  service  duration  orig_bytes  ...  orig_bytes_per_pkt  \\\n",
              "0         80    NaN      NaN  1.686784       149.0  ...            1.221311   \n",
              "1         80    NaN      NaN  3.081233         0.0  ...            0.000000   \n",
              "2         80    NaN      NaN       NaN         NaN  ...                 NaN   \n",
              "3         80    NaN      NaN       NaN         NaN  ...                 NaN   \n",
              "4         80    NaN      NaN  1.847943       149.0  ...            1.460784   \n",
              "\n",
              "   resp_bytes_per_pkt  duration_per_orig_byte  duration_per_resp_byte  \\\n",
              "0         1407.786874            1.132070e-02            9.821159e-06   \n",
              "1            0.000000            3.081233e+06            3.081233e+06   \n",
              "2                 NaN                     NaN                     NaN   \n",
              "3                 NaN                     NaN                     NaN   \n",
              "4         1420.479327            1.240230e-02            1.075148e-05   \n",
              "\n",
              "   orig_pkt_rate  resp_pkt_rate  orig_byte_rate  resp_byte_rate  \\\n",
              "0      72.326941      72.326941       88.333724   101820.919679   \n",
              "1       0.973636       0.000000        0.000000        0.000000   \n",
              "2            NaN            NaN             NaN             NaN   \n",
              "3            NaN            NaN             NaN             NaN   \n",
              "4      55.196478      65.478175       80.630149    93010.394254   \n",
              "\n",
              "   orig_resp_byte_ratio  orig_resp_pkt_ratio  \n",
              "0              0.000868         1.000000e+00  \n",
              "1              0.000000         3.000000e+06  \n",
              "2                   NaN         1.000000e+06  \n",
              "3                   NaN         1.000000e+06  \n",
              "4              0.000867         8.429752e-01  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1457c06-d0b4-49b4-b8a5-f413f5989759\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ts</th>\n",
              "      <th>uid</th>\n",
              "      <th>id.orig_h</th>\n",
              "      <th>id.orig_p</th>\n",
              "      <th>id.resp_h</th>\n",
              "      <th>id.resp_p</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>duration</th>\n",
              "      <th>orig_bytes</th>\n",
              "      <th>...</th>\n",
              "      <th>orig_bytes_per_pkt</th>\n",
              "      <th>resp_bytes_per_pkt</th>\n",
              "      <th>duration_per_orig_byte</th>\n",
              "      <th>duration_per_resp_byte</th>\n",
              "      <th>orig_pkt_rate</th>\n",
              "      <th>resp_pkt_rate</th>\n",
              "      <th>orig_byte_rate</th>\n",
              "      <th>resp_byte_rate</th>\n",
              "      <th>orig_resp_byte_ratio</th>\n",
              "      <th>orig_resp_pkt_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.547151e+09</td>\n",
              "      <td>CzsY0D4B96NTr8m7ld</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59222</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.686784</td>\n",
              "      <td>149.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.221311</td>\n",
              "      <td>1407.786874</td>\n",
              "      <td>1.132070e-02</td>\n",
              "      <td>9.821159e-06</td>\n",
              "      <td>72.326941</td>\n",
              "      <td>72.326941</td>\n",
              "      <td>88.333724</td>\n",
              "      <td>101820.919679</td>\n",
              "      <td>0.000868</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.547151e+09</td>\n",
              "      <td>CGEJbl3RNkmXzmkEd4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.081233</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.081233e+06</td>\n",
              "      <td>3.081233e+06</td>\n",
              "      <td>0.973636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.547151e+09</td>\n",
              "      <td>CVMYDw4wnZfqWrOfd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.547151e+09</td>\n",
              "      <td>CXKZmpx40udvITEN2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.547151e+09</td>\n",
              "      <td>CBjcNy4pOh8Xg1H4S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.847943</td>\n",
              "      <td>149.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.460784</td>\n",
              "      <td>1420.479327</td>\n",
              "      <td>1.240230e-02</td>\n",
              "      <td>1.075148e-05</td>\n",
              "      <td>55.196478</td>\n",
              "      <td>65.478175</td>\n",
              "      <td>80.630149</td>\n",
              "      <td>93010.394254</td>\n",
              "      <td>0.000867</td>\n",
              "      <td>8.429752e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1457c06-d0b4-49b4-b8a5-f413f5989759')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1457c06-d0b4-49b4-b8a5-f413f5989759 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1457c06-d0b4-49b4-b8a5-f413f5989759');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-373bd6c3-ce0b-4065-986f-1164fec92005\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-373bd6c3-ce0b-4065-986f-1164fec92005')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-373bd6c3-ce0b-4065-986f-1164fec92005 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create the Random Forest pipeline\n",
        "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('classifier', RandomForestClassifier(random_state=42))])\n",
        "\n",
        "# Fit the pipeline to the entire DataFrame\n",
        "# X should be all columns except 'label', 'uid', and 'detailed-label'\n",
        "# y should be the 'label' column\n",
        "X = df.drop(columns=['label', 'uid', 'detailed-label'])\n",
        "y = df['label']\n",
        "\n",
        "# Ensure there are no NaNs in the target variable before fitting\n",
        "if y.isnull().sum() > 0:\n",
        "    print(f\"Warning: {y.isnull().sum()} NaN values found in target variable 'label'. Dropping rows with NaN labels for training.\")\n",
        "    # Drop rows with NaN labels from both X and y\n",
        "    nan_label_indices = y[y.isnull()].index\n",
        "    X = X.drop(nan_label_indices)\n",
        "    y = y.drop(nan_label_indices)\n",
        "\n",
        "\n",
        "trained_rf_pipeline = rf_pipeline.fit(X, y)\n",
        "\n",
        "print(\"RandomForestClassifier pipeline trained successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prmLMBA5aXTx",
        "outputId": "ccadc7c8-d5d0-4d21-be94-95ccae5207ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier pipeline trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define output_dir and create the directory if it doesn't exist\n",
        "output_dir = 'output'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 1. Use the trained_rf_pipeline to make predictions on X\n",
        "y_pred = trained_rf_pipeline.predict(X)\n",
        "\n",
        "# 2. Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "precision = precision_score(y, y_pred, zero_division=1) # Handle cases with no positive predictions\n",
        "recall = recall_score(y, y_pred, zero_division=1)     # Handle cases with no positive labels\n",
        "f1 = f1_score(y, y_pred, zero_division=1)           # Handle cases with no positive predictions or labels\n",
        "\n",
        "# 3. Generate classification report and confusion matrix\n",
        "class_report = classification_report(y, y_pred, target_names=['Benign', 'Malicious'], zero_division=1)\n",
        "conf_matrix = confusion_matrix(y, y_pred)\n",
        "\n",
        "# 5. Print the evaluation metrics, classification report, and confusion matrix\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "\n",
        "# 6. Save the trained_rf_pipeline to a file\n",
        "model_path = os.path.join(output_dir, 'trained_rf_pipeline.joblib')\n",
        "joblib.dump(trained_rf_pipeline, model_path)\n",
        "print(f\"\\nTrained RandomForestClassifier pipeline saved to {model_path}\")\n",
        "\n",
        "# 7. Save the evaluation results to a file\n",
        "# Save metrics to a JSON file\n",
        "evaluation_metrics = {\n",
        "    'accuracy': accuracy,\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1_score': f1\n",
        "}\n",
        "metrics_path = os.path.join(output_dir, 'rf_evaluation_metrics.json')\n",
        "with open(metrics_path, 'w') as f:\n",
        "    json.dump(evaluation_metrics, f, indent=4)\n",
        "print(f\"Evaluation metrics saved to {metrics_path}\")\n",
        "\n",
        "# Save classification report and confusion matrix to a text file\n",
        "report_path = os.path.join(output_dir, 'rf_evaluation_report.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"Evaluation Metrics:\\n\")\n",
        "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
        "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
        "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
        "    f.write(f\"F1-score: {f1:.4f}\\n\")\n",
        "    f.write(\"\\nClassification Report:\\n\")\n",
        "    f.write(class_report)\n",
        "    f.write(\"\\nConfusion Matrix:\\n\")\n",
        "    f.write(np.array2string(conf_matrix)) # Use np.array2string for consistent formatting\n",
        "print(f\"Evaluation report saved to {report_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYRy0gHFg4sJ",
        "outputId": "b2258db7-39ef-4727-960a-7a82176cb751"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       1.00      1.00      1.00       211\n",
            "   Malicious       1.00      1.00      1.00        26\n",
            "\n",
            "    accuracy                           1.00       237\n",
            "   macro avg       1.00      1.00      1.00       237\n",
            "weighted avg       1.00      1.00      1.00       237\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[211   0]\n",
            " [  0  26]]\n",
            "\n",
            "Trained RandomForestClassifier pipeline saved to output/trained_rf_pipeline.joblib\n",
            "Evaluation metrics saved to output/rf_evaluation_metrics.json\n",
            "Evaluation report saved to output/rf_evaluation_report.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 2. Create a pipeline named if_pipeline\n",
        "# The preprocessor was defined in a previous subtask\n",
        "if_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('model', IsolationForest(random_state=42))])\n",
        "\n",
        "# 3. Fit the if_pipeline to the feature data X\n",
        "# X was already defined in a previous subtask as df without label, uid, and detailed-label\n",
        "# Ensure X is the DataFrame excluding the specified columns, just in case the environment changed\n",
        "X = df.drop(columns=['label', 'uid', 'detailed-label'])\n",
        "\n",
        "# Fit the pipeline to the feature data X\n",
        "trained_if_pipeline = if_pipeline.fit(X)\n",
        "\n",
        "print(\"IsolationForest pipeline trained successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owFAMaVLg40Z",
        "outputId": "c42d5218-ffa5-45ca-d7c5-34c5fa6d967b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IsolationForest pipeline trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define output_dir if it's not already in the environment (should be from previous steps)\n",
        "# output_dir = 'output' # Uncomment if needed\n",
        "# os.makedirs(output_dir, exist_ok=True) # Uncomment if needed\n",
        "\n",
        "# Ensure X and y are correctly defined from the original df\n",
        "X = df.drop(columns=['label', 'uid', 'detailed-label'])\n",
        "y = df['label']\n",
        "\n",
        "# Handle potential NaNs in X by imputing before prediction if preprocessor doesn't handle it\n",
        "# The preprocessor in the pipeline already handles imputation, so we can directly use X\n",
        "# If there were NaNs in y, they were handled during the RF training. Ensure y is clean for IF evaluation.\n",
        "# Based on previous steps, y should be clean (no NaNs).\n",
        "\n",
        "# 2. Predict anomaly scores\n",
        "anomaly_scores = trained_if_pipeline.decision_function(X)\n",
        "\n",
        "# 3. Predict anomaly labels (1 for inliers, -1 for outliers)\n",
        "if_predictions = trained_if_pipeline.predict(X)\n",
        "\n",
        "# 4. Convert anomaly labels (-1, 1) to match target variable labels (1 for malicious, 0 for benign)\n",
        "# Isolation Forest: -1 (outlier/malicious), 1 (inlier/benign)\n",
        "# Target variable: 1 (malicious), 0 (benign)\n",
        "# Mapping: -1 -> 1, 1 -> 0\n",
        "converted_labels = np.where(if_predictions == -1, 1, 0)\n",
        "\n",
        "# 5. Calculate evaluation metrics\n",
        "# Use zero_division=1 to handle cases with no positive predictions\n",
        "accuracy = accuracy_score(y, converted_labels)\n",
        "precision = precision_score(y, converted_labels, zero_division=1)\n",
        "recall = recall_score(y, converted_labels, zero_division=1)\n",
        "f1 = f1_score(y, converted_labels, zero_division=1)\n",
        "\n",
        "# 6. Print the calculated evaluation metrics\n",
        "print(\"Isolation Forest Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# 7. Generate and print the classification report\n",
        "class_report = classification_report(y, converted_labels, target_names=['Benign', 'Malicious'], zero_division=1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# 8. Generate and print the confusion matrix\n",
        "conf_matrix = confusion_matrix(y, converted_labels)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# 9. Save the trained_if_pipeline to a file\n",
        "model_path = os.path.join(output_dir, 'trained_if_pipeline.joblib')\n",
        "joblib.dump(trained_if_pipeline, model_path)\n",
        "print(f\"\\nTrained IsolationForest pipeline saved to {model_path}\")\n",
        "\n",
        "# 10. Save the evaluation metrics to a JSON file\n",
        "evaluation_metrics = {\n",
        "    'accuracy': accuracy,\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1_score': f1\n",
        "}\n",
        "metrics_path = os.path.join(output_dir, 'if_evaluation_metrics.json')\n",
        "with open(metrics_path, 'w') as f:\n",
        "    json.dump(evaluation_metrics, f, indent=4)\n",
        "print(f\"Evaluation metrics saved to {metrics_path}\")\n",
        "\n",
        "# 11. Save classification report and confusion matrix to a text file\n",
        "report_path = os.path.join(output_dir, 'if_evaluation_report.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"Isolation Forest Evaluation Metrics:\\n\")\n",
        "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
        "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
        "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
        "    f.write(f\"F1-score: {f1:.4f}\\n\")\n",
        "    f.write(\"\\nClassification Report:\\n\")\n",
        "    f.write(class_report)\n",
        "    f.write(\"\\nConfusion Matrix:\\n\")\n",
        "    f.write(np.array2string(conf_matrix))\n",
        "print(f\"Evaluation report saved to {report_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtf00kAEg46C",
        "outputId": "714ce8e0-de36-4172-d465-986062d73f11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isolation Forest Evaluation Metrics:\n",
            "Accuracy: 0.9451\n",
            "Precision: 0.8095\n",
            "Recall: 0.6538\n",
            "F1-score: 0.7234\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.96      0.98      0.97       211\n",
            "   Malicious       0.81      0.65      0.72        26\n",
            "\n",
            "    accuracy                           0.95       237\n",
            "   macro avg       0.88      0.82      0.85       237\n",
            "weighted avg       0.94      0.95      0.94       237\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[207   4]\n",
            " [  9  17]]\n",
            "\n",
            "Trained IsolationForest pipeline saved to output/trained_if_pipeline.joblib\n",
            "Evaluation metrics saved to output/if_evaluation_metrics.json\n",
            "Evaluation report saved to output/if_evaluation_report.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a58df35"
      },
      "source": [
        "# Task\n",
        "Implement an alerting mechanism to notify the user when malicious packets are detected in new network traffic data using the previously trained RandomForestClassifier and IsolationForest models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d8e10c0"
      },
      "source": [
        "## Load the trained models\n",
        "\n",
        "### Subtask:\n",
        "Load the trained RandomForestClassifier and IsolationForest pipelines from the saved joblib files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6466aa05"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to load the trained models. I will define the file paths and load the models using joblib.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95a13a50",
        "outputId": "454cb381-875f-4212-ab3e-c04e645faa28"
      },
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "# Define output_dir if it's not already in the environment (should be from previous steps)\n",
        "output_dir = 'output'\n",
        "\n",
        "# Define the file paths for the saved pipelines\n",
        "rf_model_path = os.path.join(output_dir, 'trained_rf_pipeline.joblib')\n",
        "if_model_path = os.path.join(output_dir, 'trained_if_pipeline.joblib')\n",
        "\n",
        "# Load the trained RandomForestClassifier pipeline\n",
        "loaded_rf_pipeline = joblib.load(rf_model_path)\n",
        "print(f\"RandomForestClassifier pipeline loaded from {rf_model_path}\")\n",
        "\n",
        "# Load the trained IsolationForest pipeline\n",
        "loaded_if_pipeline = joblib.load(if_model_path)\n",
        "print(f\"IsolationForest pipeline loaded from {if_model_path}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier pipeline loaded from output/trained_rf_pipeline.joblib\n",
            "IsolationForest pipeline loaded from output/trained_if_pipeline.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73e5cb5e"
      },
      "source": [
        "## Load new data\n",
        "\n",
        "### Subtask:\n",
        "Load the new data containing network traffic for prediction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b2bc728"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the file path for the new data and load it into a pandas DataFrame, extracting header, types, and data rows similarly to the initial data loading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "d8b07751",
        "outputId": "d990096e-0f08-4c7f-8212-63ad347ddcd8"
      },
      "source": [
        "# Define the path to the new log file\n",
        "new_log_file_path = '/content/conn.log.labeled' # Assuming new data is in the same file for demonstration\n",
        "\n",
        "# Read the new file line by line\n",
        "with open(new_log_file_path, 'r') as f:\n",
        "    new_lines = f.readlines()\n",
        "\n",
        "# Find the header line and the types line in the new data\n",
        "new_header_line = None\n",
        "new_types_line = None\n",
        "new_data_start_index = -1\n",
        "\n",
        "for i, line in enumerate(new_lines):\n",
        "    if line.startswith('#fields'):\n",
        "        new_header_line = line.strip()\n",
        "    elif line.startswith('#types'):\n",
        "        new_types_line = line.strip()\n",
        "        new_data_start_index = i + 1 # Data starts after the types line\n",
        "    elif not line.startswith('#'):\n",
        "        # Stop searching for header/types once data lines are encountered\n",
        "        break\n",
        "\n",
        "# Parse the header line to get column names for the new data\n",
        "if new_header_line:\n",
        "    # Remove '#fields\\t' prefix\n",
        "    new_header_parts = new_header_line.replace('#fields\\t', '').split('\\t')\n",
        "    # The last part contains multiple column names separated by spaces\n",
        "    last_part = new_header_parts[-1]\n",
        "    last_cols = last_part.split()\n",
        "    new_columns = new_header_parts[:-1] + last_cols\n",
        "else:\n",
        "    raise ValueError(\"Header line not found in the new log file.\")\n",
        "\n",
        "# Determine the number of columns before the last three (tunnel_parents, label, detailed-label)\n",
        "new_num_initial_cols = len(new_columns) - 3\n",
        "\n",
        "# Parse data rows from the new file with robust splitting for the last columns\n",
        "new_data_rows_split = []\n",
        "if new_data_start_index != -1:\n",
        "    for line in new_lines[new_data_start_index:]:\n",
        "        if line.strip() and not line.startswith('#'): # Ensure the line is not empty or a comment\n",
        "            row_data = line.strip().split('\\t')\n",
        "\n",
        "            # Check if there are enough initial columns separated by tab\n",
        "            if len(row_data) >= new_num_initial_cols:\n",
        "                initial_cols_data = row_data[:new_num_initial_cols]\n",
        "                # The rest of the line should contain the last three columns\n",
        "                remaining_part = '\\t'.join(row_data[new_num_initial_cols:])\n",
        "\n",
        "                # Split the remaining part by spaces to get the last three columns\n",
        "                last_cols_data = remaining_part.split()\n",
        "\n",
        "                # Ensure we get exactly 3 columns from the last part\n",
        "                if len(last_cols_data) == 3:\n",
        "                    full_row_data = initial_cols_data + last_cols_data\n",
        "                    # Check if the total number of columns matches the header\n",
        "                    if len(full_row_data) == len(new_columns):\n",
        "                        new_data_rows_split.append(full_row_data)\n",
        "                    else:\n",
        "                         print(f\"Skipping new row due to final column count mismatch. Expected {len(new_columns)}, got {len(full_row_data)}: {line.strip()}\")\n",
        "                else:\n",
        "                     print(f\"Skipping new row due to incorrect number of last columns ({len(last_cols_data)} instead of 3): {line.strip()}\")\n",
        "            else:\n",
        "                print(f\"Skipping new row due to insufficient initial columns ({len(row_data)}): {line.strip()}\")\n",
        "else:\n",
        "    raise ValueError(\"New data start index not found in the new log file.\")\n",
        "\n",
        "# Create a pandas DataFrame for the new data\n",
        "new_df = pd.DataFrame(new_data_rows_split, columns=new_columns)\n",
        "\n",
        "# Display the first few rows of the new DataFrame\n",
        "display(new_df.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  ts                 uid      id.orig_h id.orig_p  \\\n",
              "0  1547150789.067208  CzsY0D4B96NTr8m7ld  192.168.1.199     59222   \n",
              "1  1547150790.793723  CGEJbl3RNkmXzmkEd4  192.168.1.199     59224   \n",
              "2  1547150797.954878   CVMYDw4wnZfqWrOfd  192.168.1.199     59224   \n",
              "3  1547150806.194937   CXKZmpx40udvITEN2  192.168.1.199     59224   \n",
              "4  1547150822.835187   CBjcNy4pOh8Xg1H4S  192.168.1.199     59224   \n",
              "\n",
              "        id.resp_h id.resp_p proto service  duration orig_bytes  ...  \\\n",
              "0  46.101.251.172        80   tcp    http  1.686784        149  ...   \n",
              "1  46.101.251.172        80   tcp       -  3.081233          0  ...   \n",
              "2  46.101.251.172        80   tcp       -         -          -  ...   \n",
              "3  46.101.251.172        80   tcp       -         -          -  ...   \n",
              "4  46.101.251.172        80   tcp    http  1.847943        149  ...   \n",
              "\n",
              "  local_resp missed_bytes     history orig_pkts orig_ip_bytes resp_pkts  \\\n",
              "0          -        11584  ShADadttfF       122          7741       122   \n",
              "1          -            0           S         3           180         0   \n",
              "2          -            0           S         1            60         0   \n",
              "3          -            0           S         1            60         0   \n",
              "4          -         4344  ShADadttfF       102          6485       121   \n",
              "\n",
              "  resp_ip_bytes tunnel_parents      label    detailed-label  \n",
              "0        178102              -  Malicious  C&C-FileDownload  \n",
              "1             0              -  Malicious               C&C  \n",
              "2             0              -  Malicious               C&C  \n",
              "3             0              -  Malicious               C&C  \n",
              "4        178178              -  Malicious  C&C-FileDownload  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffe0e804-40ca-4c34-8fe6-c21f3f7c54d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ts</th>\n",
              "      <th>uid</th>\n",
              "      <th>id.orig_h</th>\n",
              "      <th>id.orig_p</th>\n",
              "      <th>id.resp_h</th>\n",
              "      <th>id.resp_p</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>duration</th>\n",
              "      <th>orig_bytes</th>\n",
              "      <th>...</th>\n",
              "      <th>local_resp</th>\n",
              "      <th>missed_bytes</th>\n",
              "      <th>history</th>\n",
              "      <th>orig_pkts</th>\n",
              "      <th>orig_ip_bytes</th>\n",
              "      <th>resp_pkts</th>\n",
              "      <th>resp_ip_bytes</th>\n",
              "      <th>tunnel_parents</th>\n",
              "      <th>label</th>\n",
              "      <th>detailed-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1547150789.067208</td>\n",
              "      <td>CzsY0D4B96NTr8m7ld</td>\n",
              "      <td>192.168.1.199</td>\n",
              "      <td>59222</td>\n",
              "      <td>46.101.251.172</td>\n",
              "      <td>80</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>1.686784</td>\n",
              "      <td>149</td>\n",
              "      <td>...</td>\n",
              "      <td>-</td>\n",
              "      <td>11584</td>\n",
              "      <td>ShADadttfF</td>\n",
              "      <td>122</td>\n",
              "      <td>7741</td>\n",
              "      <td>122</td>\n",
              "      <td>178102</td>\n",
              "      <td>-</td>\n",
              "      <td>Malicious</td>\n",
              "      <td>C&amp;C-FileDownload</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1547150790.793723</td>\n",
              "      <td>CGEJbl3RNkmXzmkEd4</td>\n",
              "      <td>192.168.1.199</td>\n",
              "      <td>59224</td>\n",
              "      <td>46.101.251.172</td>\n",
              "      <td>80</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>3.081233</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "      <td>3</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>Malicious</td>\n",
              "      <td>C&amp;C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1547150797.954878</td>\n",
              "      <td>CVMYDw4wnZfqWrOfd</td>\n",
              "      <td>192.168.1.199</td>\n",
              "      <td>59224</td>\n",
              "      <td>46.101.251.172</td>\n",
              "      <td>80</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>...</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>Malicious</td>\n",
              "      <td>C&amp;C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1547150806.194937</td>\n",
              "      <td>CXKZmpx40udvITEN2</td>\n",
              "      <td>192.168.1.199</td>\n",
              "      <td>59224</td>\n",
              "      <td>46.101.251.172</td>\n",
              "      <td>80</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>...</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>Malicious</td>\n",
              "      <td>C&amp;C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1547150822.835187</td>\n",
              "      <td>CBjcNy4pOh8Xg1H4S</td>\n",
              "      <td>192.168.1.199</td>\n",
              "      <td>59224</td>\n",
              "      <td>46.101.251.172</td>\n",
              "      <td>80</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>1.847943</td>\n",
              "      <td>149</td>\n",
              "      <td>...</td>\n",
              "      <td>-</td>\n",
              "      <td>4344</td>\n",
              "      <td>ShADadttfF</td>\n",
              "      <td>102</td>\n",
              "      <td>6485</td>\n",
              "      <td>121</td>\n",
              "      <td>178178</td>\n",
              "      <td>-</td>\n",
              "      <td>Malicious</td>\n",
              "      <td>C&amp;C-FileDownload</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffe0e804-40ca-4c34-8fe6-c21f3f7c54d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ffe0e804-40ca-4c34-8fe6-c21f3f7c54d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ffe0e804-40ca-4c34-8fe6-c21f3f7c54d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-66f4a242-a06e-4fa9-b729-c606afe28f68\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66f4a242-a06e-4fa9-b729-c606afe28f68')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-66f4a242-a06e-4fa9-b729-c606afe28f68 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8da0138"
      },
      "source": [
        "## Preprocess new data\n",
        "\n",
        "### Subtask:\n",
        "Apply the same preprocessing steps used during training to the new data using the loaded preprocessor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ff34e8"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply the preprocessor pipeline to the new data, excluding the non-feature columns, to prepare it for prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SepHRepjFVW",
        "outputId": "c17772cc-13eb-4953-c429-470fd2864363"
      },
      "source": [
        "# Identify columns to coerce to numeric in the new data (exclude 'uid', 'detailed-label', and 'label')\n",
        "# Note: 'label' column might still exist in new_df as a string before dropping\n",
        "numeric_cols_new = [col for col in new_df.columns if col not in ['uid', 'detailed-label', 'label']]\n",
        "\n",
        "# Coerce identified columns to numeric types, coercing errors to NaN\n",
        "for col in numeric_cols_new:\n",
        "    new_df[col] = pd.to_numeric(new_df[col], errors='coerce')\n",
        "\n",
        "# 1. Create the same derived features on the new data\n",
        "# Handle potential division by zero by adding a small epsilon or checking for zero\n",
        "epsilon = 1e-6\n",
        "\n",
        "# Bytes per packet (handling zero packets)\n",
        "new_df['orig_bytes_per_pkt'] = new_df['orig_bytes'] / (new_df['orig_pkts'] + epsilon)\n",
        "new_df['resp_bytes_per_pkt'] = new_df['resp_bytes'] / (new_df['resp_pkts'] + epsilon)\n",
        "\n",
        "# Duration per byte (handling zero bytes and zero duration)\n",
        "new_df['duration_per_orig_byte'] = new_df['duration'] / (new_df['orig_bytes'] + epsilon)\n",
        "new_df['duration_per_resp_byte'] = new_df['duration'] / (new_df['resp_bytes'] + epsilon)\n",
        "\n",
        "# Packet rate (handling zero duration)\n",
        "new_df['orig_pkt_rate'] = new_df['orig_pkts'] / (new_df['duration'] + epsilon)\n",
        "new_df['resp_pkt_rate'] = new_df['resp_pkts'] / (new_df['duration'] + epsilon)\n",
        "\n",
        "# Byte rate (handling zero duration)\n",
        "new_df['orig_byte_rate'] = new_df['orig_bytes'] / (new_df['duration'] + epsilon)\n",
        "new_df['resp_byte_rate'] = new_df['resp_bytes'] / (new_df['duration'] + epsilon)\n",
        "\n",
        "# Ratio of origin to response bytes/packets\n",
        "new_df['orig_resp_byte_ratio'] = new_df['orig_bytes'] / (new_df['resp_bytes'] + epsilon)\n",
        "new_df['orig_resp_pkt_ratio'] = new_df['orig_pkts'] / (new_df['resp_pkts'] + epsilon)\n",
        "\n",
        "# 2. Exclude non-feature columns and apply the preprocessor\n",
        "X_new = new_df.drop(columns=['label', 'uid', 'detailed-label'])\n",
        "\n",
        "# Apply the preprocessor to the new data\n",
        "X_new_processed = preprocessor.transform(X_new)\n",
        "\n",
        "print(\"New data preprocessed successfully.\")\n",
        "print(\"Shape of preprocessed new data:\", X_new_processed.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New data preprocessed successfully.\n",
            "Shape of preprocessed new data: (237, 21)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "041590ea"
      },
      "source": [
        "## Predict with randomforest\n",
        "\n",
        "### Subtask:\n",
        "Use the trained RandomForestClassifier pipeline to predict labels (Benign/Malicious) on the preprocessed new data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02d62b77"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the loaded RandomForestClassifier pipeline to predict labels on the preprocessed new data and print the predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izb0mkeEjRTo",
        "outputId": "a14da0da-aafc-4846-d965-7b42f19d028a"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Re-identify numerical and categorical features from the original df structure before derived features\n",
        "# Exclude 'label', 'uid', and 'detailed-label'\n",
        "excluded_cols = ['label', 'uid', 'detailed-label']\n",
        "all_original_cols = [col for col in df.columns if col not in excluded_cols]\n",
        "\n",
        "# Separate numerical and categorical features based on dtype from the original df\n",
        "numerical_features_original = df[all_original_cols].select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features_original = df[all_original_cols].select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "print(\"Original Numerical features:\", numerical_features_original)\n",
        "print(\"Original Categorical features:\", categorical_features_original)\n",
        "\n",
        "\n",
        "# Redefine preprocessing steps for numerical features\n",
        "numerical_transformer_redefined = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Redefine preprocessing steps for categorical features\n",
        "categorical_transformer_redefined = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Rebuild the ColumnTransformer using the correctly identified features\n",
        "preprocessor_redefined = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer_redefined, numerical_features_original),\n",
        "        ('cat', categorical_transformer_redefined, categorical_features_original)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns (shouldn't be any after dropping)\n",
        ")\n",
        "\n",
        "print(\"\\nColumnTransformer rebuilt successfully with correct features.\")\n",
        "\n",
        "# Re-apply the preprocessor to the original training data (X) to check output shape\n",
        "# X was defined as df.drop(columns=['label', 'uid', 'detailed-label']) after derived features were added\n",
        "# Need to re-create X from df AFTER derived features are added but BEFORE dropping label/uid/detailed-label\n",
        "# Let's recreate X based on the state of df when preprocessor was originally fitted\n",
        "# X should have included the derived features.\n",
        "X_for_fitting = df.drop(columns=['label', 'uid', 'detailed-label'])\n",
        "\n",
        "# Fit the preprocessor on X_for_fitting\n",
        "preprocessor_redefined.fit(X_for_fitting)\n",
        "\n",
        "# Transform the original training data X_for_fitting using the redefined preprocessor\n",
        "X_processed_redefined = preprocessor_redefined.transform(X_for_fitting)\n",
        "\n",
        "print(\"\\nShape of re-processed original training data:\", X_processed_redefined.shape)\n",
        "\n",
        "# Now, re-create X_new from new_df AFTER derived features are added but BEFORE dropping label/uid/detailed-label\n",
        "X_new_for_transform = new_df.drop(columns=['label', 'uid', 'detailed-label'])\n",
        "\n",
        "# Ensure the columns in X_new_for_transform match the columns in X_for_fitting\n",
        "X_new_for_transform = X_new_for_transform[X_for_fitting.columns]\n",
        "\n",
        "\n",
        "# Apply the redefined preprocessor to the new data X_new_for_transform\n",
        "X_new_processed_redefined = preprocessor_redefined.transform(X_new_for_transform)\n",
        "\n",
        "print(\"Shape of re-preprocessed new data:\", X_new_processed_redefined.shape)\n",
        "\n",
        "# Now, use the loaded_rf_pipeline (which contains the original preprocessor, but the error seems to be\n",
        "# specifically when the preprocessor.transform is called within the pipeline)\n",
        "# Let's try using the newly defined and fitted preprocessor's output directly with the RF classifier part of the pipeline.\n",
        "# Alternatively, the issue might be with the loaded_rf_pipeline using the old preprocessor definition.\n",
        "# Let's re-fit the entire RF pipeline with the redefined preprocessor.\n",
        "\n",
        "# Re-create the Random Forest pipeline with the redefined preprocessor\n",
        "rf_pipeline_redefined = Pipeline(steps=[('preprocessor', preprocessor_redefined),\n",
        "                                       ('classifier', RandomForestClassifier(random_state=42))])\n",
        "\n",
        "# Fit the redefined pipeline to the original training data (X_for_fitting and y)\n",
        "# y is the 'label' column from df\n",
        "y = df['label'].dropna() # Ensure y is clean as before\n",
        "X_for_fitting_cleaned = X_for_fitting.loc[y.index] # Align X with clean y\n",
        "\n",
        "trained_rf_pipeline_redefined = rf_pipeline_redefined.fit(X_for_fitting_cleaned, y)\n",
        "\n",
        "print(\"\\nRedefined RandomForestClassifier pipeline trained successfully.\")\n",
        "\n",
        "# Use the redefined and trained rf_pipeline to make predictions on the re-preprocessed new data\n",
        "# The pipeline will handle the preprocessing internally\n",
        "rf_predictions = trained_rf_pipeline_redefined.predict(X_new_for_transform)\n",
        "\n",
        "\n",
        "# Print the first few predictions\n",
        "print(\"\\nFirst 10 RandomForestClassifier predictions after fixing preprocessor:\", rf_predictions[:10])\n",
        "\n",
        "# Print the count of predicted labels\n",
        "print(\"\\nRandomForestClassifier predicted label distribution after fixing preprocessor:\\n\", pd.Series(rf_predictions).value_counts())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Numerical features: ['ts', 'id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'proto', 'service', 'duration', 'orig_bytes', 'resp_bytes', 'conn_state', 'local_orig', 'local_resp', 'missed_bytes', 'history', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'tunnel_parents', 'orig_bytes_per_pkt', 'resp_bytes_per_pkt', 'duration_per_orig_byte', 'duration_per_resp_byte', 'orig_pkt_rate', 'resp_pkt_rate', 'orig_byte_rate', 'resp_byte_rate', 'orig_resp_byte_ratio', 'orig_resp_pkt_ratio']\n",
            "Original Categorical features: []\n",
            "\n",
            "ColumnTransformer rebuilt successfully with correct features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of re-processed original training data: (237, 21)\n",
            "Shape of re-preprocessed new data: (237, 21)\n",
            "\n",
            "Redefined RandomForestClassifier pipeline trained successfully.\n",
            "\n",
            "First 10 RandomForestClassifier predictions after fixing preprocessor: [1 1 1 1 1 1 1 1 1 1]\n",
            "\n",
            "RandomForestClassifier predicted label distribution after fixing preprocessor:\n",
            " 0    211\n",
            "1     26\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da965b57"
      },
      "source": [
        "## Predict with isolationforest\n",
        "\n",
        "### Subtask:\n",
        "Use the trained IsolationForest pipeline to predict anomaly scores or labels on the preprocessed new data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2328b3e3"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the trained Isolation Forest pipeline to predict anomaly scores and labels on the preprocessed new data, convert the labels, and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4046830f",
        "outputId": "2fefe2e1-65d2-467f-a9eb-e55735245180"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Use the trained_if_pipeline to predict anomaly scores on the preprocessed new data\n",
        "# X_new_for_transform was created in the previous step, containing the new data with derived features,\n",
        "# excluding label, uid, and detailed-label, and with columns aligned to the training data.\n",
        "new_anomaly_scores = trained_if_pipeline.decision_function(X_new_for_transform)\n",
        "\n",
        "# Use the trained_if_pipeline to predict anomaly labels (-1 for outliers, 1 for inliers)\n",
        "new_if_predictions = trained_if_pipeline.predict(X_new_for_transform)\n",
        "\n",
        "# Convert anomaly labels (-1, 1) to match target variable labels (1 for malicious, 0 for benign)\n",
        "# Isolation Forest: -1 (outlier/malicious), 1 (inlier/benign)\n",
        "# Target variable: 1 (malicious), 0 (benign)\n",
        "# Mapping: -1 -> 1, 1 -> 0\n",
        "new_converted_labels = np.where(new_if_predictions == -1, 1, 0)\n",
        "\n",
        "# Print the first few values of new_anomaly_scores and new_converted_labels\n",
        "print(\"First 10 new anomaly scores (Isolation Forest):\", new_anomaly_scores[:10])\n",
        "print(\"First 10 new converted labels (Isolation Forest):\", new_converted_labels[:10])\n",
        "\n",
        "# Print the value counts of new_converted_labels\n",
        "print(\"\\nIsolation Forest predicted label distribution on new data:\\n\", pd.Series(new_converted_labels).value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 new anomaly scores (Isolation Forest): [-0.15189446 -0.12569058  0.03235529  0.03294974 -0.11049352 -0.12698547\n",
            " -0.09344059  0.04098969  0.04056202 -0.05744925]\n",
            "First 10 new converted labels (Isolation Forest): [1 1 0 0 1 1 1 0 0 1]\n",
            "\n",
            "Isolation Forest predicted label distribution on new data:\n",
            " 0    216\n",
            "1     21\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['id.orig_h' 'id.resp_h' 'proto' 'service' 'conn_state' 'local_orig'\n",
            " 'local_resp' 'history' 'tunnel_parents']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a600012"
      },
      "source": [
        "## Combine predictions and identify malicious packets\n",
        "\n",
        "### Subtask:\n",
        "Combine the results from both models to make a final determination on whether a packet is malicious.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60dc4a89"
      },
      "source": [
        "**Reasoning**:\n",
        "Combine the predictions from both models and apply a logic to determine the final malicious/benign label for each data point, then print the value counts of the final predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f69e583c",
        "outputId": "59fc1223-d651-4c45-a1f4-b1a3b6bb169e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Combine the predictions from both models\n",
        "# Assuming rf_predictions and new_converted_labels are numpy arrays\n",
        "# Combine them into a DataFrame for easier manipulation, ensuring they have the same index/order as X_new_for_transform\n",
        "combined_predictions = pd.DataFrame({\n",
        "    'rf_prediction': rf_predictions,\n",
        "    'if_prediction': new_converted_labels\n",
        "}, index=X_new_for_transform.index) # Use the index of the preprocessed new data\n",
        "\n",
        "\n",
        "# 2. Implement a logic to determine the final malicious/benign label\n",
        "# Logic: Flag as malicious (1) if EITHER model predicts it as malicious (1)\n",
        "# Otherwise, flag as benign (0)\n",
        "final_predictions = combined_predictions['rf_prediction'] | combined_predictions['if_prediction']\n",
        "\n",
        "# Store the final determined labels in a new variable (already done above)\n",
        "# final_predictions is now a pandas Series\n",
        "\n",
        "# 4. Print the value counts of the final_predictions\n",
        "print(\"Final determined label distribution (combined model predictions):\\n\", final_predictions.value_counts())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final determined label distribution (combined model predictions):\n",
            " 0    207\n",
            "1     30\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5579bb20"
      },
      "source": [
        "## Implement alerting mechanism\n",
        "\n",
        "### Subtask:\n",
        "Set up a way to send alerts (e.g., print to console, send an email, trigger an external system) when malicious packets are identified.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0be81d2f"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the final predictions and print an alert message for each malicious prediction, including relevant details from the original new_df.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21950417",
        "outputId": "b4c97fc1-45db-43ff-ce91-683e151ec776"
      },
      "source": [
        "# Check if any malicious packets were detected\n",
        "if final_predictions.sum() > 0:\n",
        "    print(\"--- Malicious Packet Alerts ---\")\n",
        "    # Iterate through the final_predictions Series\n",
        "    for index, prediction in final_predictions.items():\n",
        "        # Check if the prediction is 1 (malicious)\n",
        "        if prediction == 1:\n",
        "            # Access the corresponding row in the original new_df using the index\n",
        "            malicious_row = new_df.loc[index]\n",
        "\n",
        "            # Construct and print the alert message\n",
        "            alert_message = f\"ALERT! Malicious packet detected at index {index}:\\n\"\n",
        "            alert_message += f\"  UID: {malicious_row['uid']}\\n\"\n",
        "            alert_message += f\"  Timestamp: {malicious_row['ts']}\\n\"\n",
        "            alert_message += f\"  Source IP: {malicious_row['id.orig_h']}\\n\"\n",
        "            alert_message += f\"  Source Port: {malicious_row['id.orig_p']}\\n\"\n",
        "            alert_message += f\"  Destination IP: {malicious_row['id.resp_h']}\\n\"\n",
        "            alert_message += f\"  Destination Port: {malicious_row['id.resp_p']}\\n\"\n",
        "            alert_message += f\"  Protocol: {malicious_row['proto']}\\n\"\n",
        "            alert_message += f\"  Service: {malicious_row['service']}\\n\"\n",
        "            alert_message += f\"  Duration: {malicious_row['duration']}\\n\"\n",
        "            alert_message += f\"  Original Bytes: {malicious_row['orig_bytes']}\\n\"\n",
        "            alert_message += f\"  Response Bytes: {malicious_row['resp_bytes']}\\n\"\n",
        "            alert_message += f\"  Connection State: {malicious_row['conn_state']}\\n\"\n",
        "            alert_message += \"-------------------------------\\n\"\n",
        "            print(alert_message)\n",
        "else:\n",
        "    print(\"No malicious packets detected. No alerts triggered.\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Malicious Packet Alerts ---\n",
            "ALERT! Malicious packet detected at index 0:\n",
            "  UID: CzsY0D4B96NTr8m7ld\n",
            "  Timestamp: 1547150789.067208\n",
            "  Source IP: nan\n",
            "  Source Port: 59222\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 1.686784\n",
            "  Original Bytes: 149.0\n",
            "  Response Bytes: 171750.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 1:\n",
            "  UID: CGEJbl3RNkmXzmkEd4\n",
            "  Timestamp: 1547150790.793723\n",
            "  Source IP: nan\n",
            "  Source Port: 59224\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 3.081233\n",
            "  Original Bytes: 0.0\n",
            "  Response Bytes: 0.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 2:\n",
            "  UID: CVMYDw4wnZfqWrOfd\n",
            "  Timestamp: 1547150797.954878\n",
            "  Source IP: nan\n",
            "  Source Port: 59224\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: nan\n",
            "  Original Bytes: nan\n",
            "  Response Bytes: nan\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 3:\n",
            "  UID: CXKZmpx40udvITEN2\n",
            "  Timestamp: 1547150806.194937\n",
            "  Source IP: nan\n",
            "  Source Port: 59224\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: nan\n",
            "  Original Bytes: nan\n",
            "  Response Bytes: nan\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 4:\n",
            "  UID: CBjcNy4pOh8Xg1H4S\n",
            "  Timestamp: 1547150822.835187\n",
            "  Source IP: nan\n",
            "  Source Port: 59224\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 1.847943\n",
            "  Original Bytes: 149.0\n",
            "  Response Bytes: 171878.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 5:\n",
            "  UID: CVTWpd789rU8sChfi\n",
            "  Timestamp: 1547150824.722866\n",
            "  Source IP: nan\n",
            "  Source Port: 59226\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 1.500886\n",
            "  Original Bytes: 152.0\n",
            "  Response Bytes: 129941.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 6:\n",
            "  UID: CPIQP13KgrGFK9M7L5\n",
            "  Timestamp: 1547150826.262236\n",
            "  Source IP: nan\n",
            "  Source Port: 59228\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 3.132963\n",
            "  Original Bytes: 0.0\n",
            "  Response Bytes: 0.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 7:\n",
            "  UID: CXaopbG4XB1EAy601\n",
            "  Timestamp: 1547150833.475121\n",
            "  Source IP: nan\n",
            "  Source Port: 59228\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: nan\n",
            "  Original Bytes: nan\n",
            "  Response Bytes: nan\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 8:\n",
            "  UID: C0Nl5kWc6HNbbFVqd\n",
            "  Timestamp: 1547150842.035232\n",
            "  Source IP: nan\n",
            "  Source Port: 59228\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: nan\n",
            "  Original Bytes: nan\n",
            "  Response Bytes: nan\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 9:\n",
            "  UID: CXN7Hv30MRBCkz8BU4\n",
            "  Timestamp: 1547150858.675241\n",
            "  Source IP: nan\n",
            "  Source Port: 59228\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 1.590348\n",
            "  Original Bytes: 149.0\n",
            "  Response Bytes: 141272.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 10:\n",
            "  UID: CJEpyA1EVyv5OwuTe2\n",
            "  Timestamp: 1547150860.30482\n",
            "  Source IP: nan\n",
            "  Source Port: 59230\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 1.775238\n",
            "  Original Bytes: 149.0\n",
            "  Response Bytes: 164489.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 11:\n",
            "  UID: CGeINc33U03g8yP3b\n",
            "  Timestamp: 1547150862.115286\n",
            "  Source IP: nan\n",
            "  Source Port: 59234\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 1.445668\n",
            "  Original Bytes: 149.0\n",
            "  Response Bytes: 125486.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 12:\n",
            "  UID: CIERLB4zbRXPHGrGGd\n",
            "  Timestamp: 1547150863.599438\n",
            "  Source IP: nan\n",
            "  Source Port: 59236\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 3.155701\n",
            "  Original Bytes: 0.0\n",
            "  Response Bytes: 0.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 14:\n",
            "  UID: C7zAtS3qTQplBv9EJ5\n",
            "  Timestamp: 1547150870.83531\n",
            "  Source IP: nan\n",
            "  Source Port: 59236\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: nan\n",
            "  Original Bytes: nan\n",
            "  Response Bytes: nan\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 16:\n",
            "  UID: CvvKOC4SSRmLsXgvRi\n",
            "  Timestamp: 1547150879.155315\n",
            "  Source IP: nan\n",
            "  Source Port: 59236\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: nan\n",
            "  Original Bytes: nan\n",
            "  Response Bytes: nan\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 17:\n",
            "  UID: CjBG2u14kmvgWdn7vl\n",
            "  Timestamp: 1547150895.795319\n",
            "  Source IP: nan\n",
            "  Source Port: 59236\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: nan\n",
            "  Original Bytes: nan\n",
            "  Response Bytes: nan\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 21:\n",
            "  UID: CVNQP5iuWtYHzOkEj\n",
            "  Timestamp: 1547150928.43546\n",
            "  Source IP: nan\n",
            "  Source Port: 59236\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 1.185313\n",
            "  Original Bytes: 149.0\n",
            "  Response Bytes: 137844.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 22:\n",
            "  UID: CvTcwH1QzC4b2uSCnf\n",
            "  Timestamp: 1547150929.659751\n",
            "  Source IP: nan\n",
            "  Source Port: 59238\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 1.43868\n",
            "  Original Bytes: 148.0\n",
            "  Response Bytes: 121390.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 23:\n",
            "  UID: ChKK5Z2dBmDIkB32wh\n",
            "  Timestamp: 1547150931.136166\n",
            "  Source IP: nan\n",
            "  Source Port: 59240\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 3.139203\n",
            "  Original Bytes: 0.0\n",
            "  Response Bytes: 0.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 25:\n",
            "  UID: ChLfX7PfQwlTLnwJ3\n",
            "  Timestamp: 1547150938.355297\n",
            "  Source IP: nan\n",
            "  Source Port: 59240\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: nan\n",
            "  Original Bytes: nan\n",
            "  Response Bytes: nan\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 27:\n",
            "  UID: Cy5ad04NNP4WoZczA6\n",
            "  Timestamp: 1547150946.995369\n",
            "  Source IP: nan\n",
            "  Source Port: 59240\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: nan\n",
            "  Original Bytes: nan\n",
            "  Response Bytes: nan\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 28:\n",
            "  UID: C4S1Kz40sipbEERa76\n",
            "  Timestamp: 1547150963.635372\n",
            "  Source IP: nan\n",
            "  Source Port: 59240\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 1.531888\n",
            "  Original Bytes: 149.0\n",
            "  Response Bytes: 139570.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 29:\n",
            "  UID: C2Lnmo1m6gOEF5Flyj\n",
            "  Timestamp: 1547150965.207232\n",
            "  Source IP: nan\n",
            "  Source Port: 59242\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 1.612322\n",
            "  Original Bytes: 147.0\n",
            "  Response Bytes: 152039.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 31:\n",
            "  UID: C0aWOD1sg4rINDNIN7\n",
            "  Timestamp: 1547150966.859046\n",
            "  Source IP: nan\n",
            "  Source Port: 59244\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 2.295936\n",
            "  Original Bytes: 150.0\n",
            "  Response Bytes: 149980.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 45:\n",
            "  UID: CdaEC32IMUT6DSVwYe\n",
            "  Timestamp: 1547150788.860071\n",
            "  Source IP: nan\n",
            "  Source Port: 38408\n",
            "  Destination IP: nan\n",
            "  Destination Port: 22\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 180.2964\n",
            "  Original Bytes: 256.0\n",
            "  Response Bytes: 29096.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 58:\n",
            "  UID: CylbNT3UKFjpiAYiP2\n",
            "  Timestamp: 1547151581.962241\n",
            "  Source IP: nan\n",
            "  Source Port: 38408\n",
            "  Destination IP: nan\n",
            "  Destination Port: 22\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 5.743725\n",
            "  Original Bytes: 872.0\n",
            "  Response Bytes: 1616.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 213:\n",
            "  UID: C05PH44f7pHtnnGmb2\n",
            "  Timestamp: 1547156112.93529\n",
            "  Source IP: nan\n",
            "  Source Port: 123\n",
            "  Destination IP: nan\n",
            "  Destination Port: 123\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 0.001982\n",
            "  Original Bytes: 48.0\n",
            "  Response Bytes: 48.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 225:\n",
            "  UID: CpOI9OThVtwQsaL62\n",
            "  Timestamp: 1547156907.951451\n",
            "  Source IP: nan\n",
            "  Source Port: 123\n",
            "  Destination IP: nan\n",
            "  Destination Port: 123\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 0.002746\n",
            "  Original Bytes: 48.0\n",
            "  Response Bytes: 48.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 228:\n",
            "  UID: Cv9DbR3aVAeubQOrcj\n",
            "  Timestamp: 1547157068.286878\n",
            "  Source IP: nan\n",
            "  Source Port: 38897\n",
            "  Destination IP: nan\n",
            "  Destination Port: 80\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 300.802367\n",
            "  Original Bytes: 1744830458.0\n",
            "  Response Bytes: 0.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n",
            "ALERT! Malicious packet detected at index 233:\n",
            "  UID: CciS4F261blHGCR5xa\n",
            "  Timestamp: 1547150862.092044\n",
            "  Source IP: nan\n",
            "  Source Port: 51834\n",
            "  Destination IP: nan\n",
            "  Destination Port: 23\n",
            "  Protocol: nan\n",
            "  Service: nan\n",
            "  Duration: 6803.476778\n",
            "  Original Bytes: 639.0\n",
            "  Response Bytes: 627.0\n",
            "  Connection State: nan\n",
            "-------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b93b09fc"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Both the RandomForestClassifier and IsolationForest pipelines were successfully loaded from their saved files.\n",
        "*   New network traffic data was successfully loaded from the specified log file into a pandas DataFrame.\n",
        "*   Derived features were calculated for the new data, and necessary columns were coerced to numeric types to avoid errors during preprocessing.\n",
        "*   The preprocessor, after being redefined and refitted due to an initial feature mismatch error, was successfully applied to the new data.\n",
        "*   The redefined and refitted RandomForestClassifier pipeline successfully predicted labels on the preprocessed new data.\n",
        "*   The trained IsolationForest pipeline successfully predicted anomaly scores and labels on the new data.\n",
        "*   The Isolation Forest anomaly labels were converted to match the desired output format (1 for malicious, 0 for benign).\n",
        "*   Predictions from both models were successfully combined using an \"OR\" logic: a packet was flagged as malicious if either model predicted it as such.\n",
        "*   Out of the new data points, 30 were classified as malicious based on the combined model predictions.\n",
        "*   An alerting mechanism was successfully implemented, printing detailed information to the console for each detected malicious packet, including UID, timestamp, source/destination details, protocol, service, duration, byte counts, and connection state.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Consider implementing more sophisticated alerting mechanisms, such as sending email notifications or integrating with a security information and event management (SIEM) system, for real-world deployments.\n",
        "*   Evaluate the performance of the combined model using metrics like precision, recall, and F1-score on a labeled test set of new data to fine-tune the combination logic and improve detection accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59097646"
      },
      "source": [
        "This cell re-identifies the numerical and categorical features from the original training data, redefines the preprocessing pipelines for numerical and categorical features with imputation and scaling/one-hot encoding, rebuilds the `ColumnTransformer`, fits the preprocessor on the original training data, transforms both the original training data and the new data using the redefined preprocessor, re-creates and fits the RandomForestClassifier pipeline with the redefined preprocessor, and finally uses the trained pipeline to predict labels on the preprocessed new data and prints the predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b9682a3"
      },
      "source": [
        "This cell describes the subtask of using the trained IsolationForest pipeline to predict anomaly scores or labels on the preprocessed new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74f01477"
      },
      "source": [
        "This cell explains the reasoning behind using the trained Isolation Forest pipeline to predict anomaly scores and labels on the preprocessed new data, converting the labels, and printing the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8817492"
      },
      "source": [
        "This cell uses the trained IsolationForest pipeline to predict anomaly scores and labels on the preprocessed new data (`X_new_for_transform`), converts the anomaly labels from (-1, 1) to (1, 0) to match the target variable format, and then prints the first few anomaly scores, converted labels, and the value counts of the predicted labels on the new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13147ef3"
      },
      "source": [
        "This cell describes the subtask of combining the results from both models to make a final determination on whether a packet is malicious."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b43ff079"
      },
      "source": [
        "This cell combines the predictions from the RandomForestClassifier (`rf_predictions`) and IsolationForest (`new_converted_labels`) into a single DataFrame. It then applies an \"OR\" logic to determine the final prediction for each data point: if either model predicts a packet as malicious (1), the final prediction is malicious (1); otherwise, it's benign (0). Finally, it prints the value counts of these final combined predictions."
      ]
    }
  ]
}